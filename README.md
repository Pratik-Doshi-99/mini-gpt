# Training a Transformer from Scratch
A project to pre-train a GPT-like language model from scratch. Code was referred from Andrej Karpathy's lecture on building GPT from scratch.

**Original Project Link**: https://github.com/karpathy/ng-video-lecture

**Youtube Tutorial**: https://youtu.be/kCc8FmEb1nY?si=cMstqwDnCIbfgdEM

**Dataset Link**: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt

**Google Colab Link**: https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing



